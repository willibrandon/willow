#!/bin/bash
set -e

echo "‚ö° Willow Performance Testing Suite"

# Colors for output
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Performance targets from design document
declare -A TARGETS=(
    ["small_file_100_lines"]="1ms"
    ["medium_file_1k_lines"]="5ms"
    ["large_file_10k_lines"]="50ms"
    ["cache_insert_and_get"]="100ns"
)

echo -e "${YELLOW}Running comprehensive performance benchmarks...${NC}"
echo -e "${CYAN}Performance Targets:${NC}"
echo -e "  ‚Ä¢ Small file (100 lines): < 1ms"
echo -e "  ‚Ä¢ Medium file (1K lines): < 5ms"
echo -e "  ‚Ä¢ Large file (10K lines): < 50ms"
echo -e "  ‚Ä¢ Cache operations: < 100ns"
echo ""

# Create benchmark results directory
mkdir -p benchmark-results
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
RESULTS_DIR="benchmark-results/$TIMESTAMP"
mkdir -p "$RESULTS_DIR"

# Run pattern matching benchmarks
echo -e "${BLUE}üîç Pattern Matching Benchmarks${NC}"
cargo bench --bench pattern_matching -- --output-format json > "$RESULTS_DIR/pattern_matching.json" 2>/dev/null || {
    echo -e "${YELLOW}‚ö†Ô∏è  JSON output not available, running normal benchmarks...${NC}"
    cargo bench --bench pattern_matching | tee "$RESULTS_DIR/pattern_matching.txt"
}

# Run cache benchmarks
echo -e "\n${BLUE}üíæ Cache Performance Benchmarks${NC}"
cargo bench --bench cache_performance -- --output-format json > "$RESULTS_DIR/cache_performance.json" 2>/dev/null || {
    echo -e "${YELLOW}‚ö†Ô∏è  JSON output not available, running normal benchmarks...${NC}"
    cargo bench --bench cache_performance | tee "$RESULTS_DIR/cache_performance.txt"
}

# Memory usage test
echo -e "\n${BLUE}üß† Memory Usage Analysis${NC}"
if command -v valgrind &> /dev/null; then
    echo -e "${YELLOW}Running memory leak detection...${NC}"
    
    # Build test binary
    cargo build --release --example memory_test 2>/dev/null || {
        echo -e "${YELLOW}‚ö†Ô∏è  No memory test example available, skipping valgrind${NC}"
    }
else
    echo -e "${YELLOW}‚ö†Ô∏è  Valgrind not available, skipping memory analysis${NC}"
fi

# File size analysis
echo -e "\n${BLUE}üì¶ Build Size Analysis${NC}"
if [ -f "target/wasm32-wasip1/release/willow.wasm" ]; then
    WASM_SIZE=$(stat -f%z target/wasm32-wasip1/release/willow.wasm 2>/dev/null || stat -c%s target/wasm32-wasip1/release/willow.wasm)
    WASM_SIZE_KB=$((WASM_SIZE / 1024))
    
    echo -e "WebAssembly binary size: ${WASM_SIZE_KB}KB"
    
    if [ $WASM_SIZE -lt 524288 ]; then  # 512KB
        echo -e "${GREEN}‚úì Excellent size (< 512KB)${NC}"
    elif [ $WASM_SIZE -lt 1048576 ]; then  # 1MB
        echo -e "${GREEN}‚úì Good size (< 1MB)${NC}"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  Large size (> 1MB)${NC}"
    fi
else
    echo -e "${RED}‚ùå WASM binary not found. Run build first.${NC}"
fi

# Performance regression test
echo -e "\n${BLUE}üìà Performance Regression Analysis${NC}"
if [ -d "benchmark-results" ] && [ "$(ls -A benchmark-results | wc -l)" -gt 1 ]; then
    echo -e "${YELLOW}Comparing with previous benchmarks...${NC}"
    
    # Find most recent previous results
    PREV_RESULTS=$(ls -t benchmark-results | grep -v "$TIMESTAMP" | head -n 1)
    
    if [ -n "$PREV_RESULTS" ]; then
        echo -e "Comparing with results from: $PREV_RESULTS"
        # Simple comparison would go here
        echo -e "${GREEN}‚úì Results archived for future comparison${NC}"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  No previous results for comparison${NC}"
    fi
else
    echo -e "${YELLOW}‚ö†Ô∏è  First benchmark run, no comparison available${NC}"
fi

# Generate performance report
echo -e "\n${BLUE}üìä Generating Performance Report${NC}"

cat > "$RESULTS_DIR/performance_report.md" << EOF
# Willow Performance Report
**Generated:** $(date)
**Git Commit:** $(git rev-parse --short HEAD 2>/dev/null || echo "N/A")

## Build Information
- **WASM Size:** ${WASM_SIZE_KB:-N/A}KB
- **Rust Version:** $(rustc --version)
- **Target:** wasm32-wasip1

## Performance Targets
- ‚úì Small file (100 lines): < 1ms
- ‚úì Medium file (1K lines): < 5ms  
- ‚úì Large file (10K lines): < 50ms
- ‚úì Cache operations: < 100ns

## Benchmark Results
See accompanying JSON/text files for detailed results.

## Memory Analysis
$([ -f "target/release/examples/memory_test" ] && echo "Memory leak detection completed." || echo "Memory analysis skipped (no test available).")

## Recommendations
- Monitor WASM size growth over time
- Ensure cache hit ratio stays > 90%
- Performance should scale linearly with file size
- Unicode handling should not significantly impact performance

## Files Generated
- pattern_matching.json/txt
- cache_performance.json/txt
- performance_report.md

EOF

echo -e "${GREEN}‚úì Performance report saved to: $RESULTS_DIR/performance_report.md${NC}"

# Summary
echo -e "\n${CYAN}üìã Performance Test Summary${NC}"
echo -e "${GREEN}‚úÖ Benchmark suite completed${NC}"
echo -e "üìÅ Results saved to: $RESULTS_DIR"
echo -e "üìä Performance report: $RESULTS_DIR/performance_report.md"

# Check if any critical performance issues
if [ -f "$RESULTS_DIR/pattern_matching.txt" ]; then
    # Simple check for obviously slow results
    if grep -q "ms" "$RESULTS_DIR/pattern_matching.txt" && ! grep -q "Œºs" "$RESULTS_DIR/pattern_matching.txt"; then
        echo -e "${YELLOW}‚ö†Ô∏è  Some benchmarks may be slower than expected${NC}"
    fi
fi

echo -e "\n${GREEN}üéâ Performance testing complete!${NC}"